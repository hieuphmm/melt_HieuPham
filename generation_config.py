GenerationConfig = {
    "question-answering": {
        "temperature": 1.0,
        "top_k": 1,
        "max_new_tokens": 100,
        "repetition_penalty": 1.1,
    },
    "summarization": {
        "temperature": 1.0,
        "top_k": 1,
        "max_new_tokens": 300,
        "repetition_penalty": 1.1,
    },
    "translation-envi": {
        "temperature": 1.0,
        "top_k": 1,
        "max_new_tokens": 500,
        "repetition_penalty": 1.1,
    },
    "translation-vien": {
        "temperature": 1.0,
        "top_k": 1,
        "max_new_tokens": 500,
        "repetition_penalty": 1.1,
    },
    "language-modelling-filling": {
        "temperature": 1.0,
        "top_k": 1,
        "max_new_tokens": 500,
        "repetition_penalty": 1.1,
    },
    "language-modelling-correction": {
        "temperature": 1.0,
        "top_k": 1,
        "max_new_tokens": 500,
        "repetition_penalty": 1.1,
    },
    "sentiment-analysis": {
        "temperature": 1.0,
        "top_k": 1,
        "max_new_tokens": 50,
        "repetition_penalty": 1.1,
    },
    "text-classification-vsmec": {
        "temperature": 1.0,
        "top_k": 1,
        "max_new_tokens": 50,
        "repetition_penalty": 1.1,
    },
    "text-classification-atis": {
        "temperature": 1.0,
        "top_k": 1,
        "max_new_tokens": 50,
        "repetition_penalty": 1.1,
    },
    "toxicity-detection-ViCTSD": {
        "temperature": 1.0,
        "top_k": 1,
        "max_new_tokens": 50,
        "repetition_penalty": 1.1,
    },
    "toxicity-detection-ViHSD": {
        "temperature": 1.0,
        "top_k": 1,
        "max_new_tokens": 50,
        "repetition_penalty": 1.1,
    },
    "knowledge-mtpchoice": {
        "temperature": 1.0,
        "top_k": 1,
        "max_new_tokens": 50,
        "repetition_penalty": 1.1,
    },
    "knowledge-openended": {
        "temperature": 1.0,
        "top_k": 1,
        "max_new_tokens": 100,
        "repetition_penalty": 1.1,
    },
    "information-retrieval": {
        "temperature": 1.0,
        "top_k": 1,
        "max_new_tokens": 50,
        "repetition_penalty": 1.1,
    },
    "reasoning-synthetic": {
        "temperature": 1.0,
        "top_k": 1,
        "max_new_tokens": 100,
        "repetition_penalty": 1.1,
    },
    "reasoning-math": {
        "temperature": 1.0,
        "top_k": 1,
        "max_new_tokens": 1000,
        "repetition_penalty": 1.1,
    },
}
